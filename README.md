# task-ETL-1

# Завдання для дата-аналітика (навчальний проєкт)

Загальний опис

Цей навчальний проєкт присвячений обробці табличних даних за допомогою бібліотеки Pandas.
У межах проєкту виконано повний цикл ETL (Extract – Transform – Load) на основі реального CSV-датасету UK-500, що містить персональні та контактні дані користувачів.

Проєкт демонструє базовий робочий процес дата-аналітика:
очищення даних, створення нових ознак, фільтрацію, сегментацію, групування та збереження результатів для подальшого аналізу.

Мета проєкту

Отримати практичний досвід роботи з бібліотекою Pandas.

Навчитись перетворювати сирі дані у структурований та аналітично готовий формат.

Підготувати DataFrame, придатний для аналізу та подальшого використання.

Основні цілі

Завантажити та дослідити вхідний датасет.

Перевірити якість даних (пропуски та дублікати).

Очистити дані та стандартизувати текстові поля.

Створити нові аналітичні колонки (feature engineering).

Виконати фільтрацію та сегментацію даних.

Провести групування та базовий статистичний аналіз.

Експортувати підготовлені результати у зовнішні формати.

План реалізації
1. Імпорт і первинний аналіз даних

Завантажено датасет UK-500 за допомогою pd.read_csv().

Проведено первинне дослідження структури даних з використанням:

df.head()

df.info()

df.describe()

2. Перевірка якості даних

Проаналізовано наявність пропущених значень (isna()).

Перевірено датасет на дублікати (duplicated()).

Оцінено стан даних перед етапом очищення.

3. Очищення даних

Створено копію DataFrame для безпечної обробки (copy()).

Видалено повністю порожні рядки.

Усунено дублікати.

Виконано базову стандартизацію текстових колонок (видалення зайвих пробілів).

4. Створення нових колонок (Feature Engineering)

Додано нові аналітичні ознаки:

full_name — обʼєднання імені та прізвища;

email_domain — домен електронної пошти;

city_length — довжина назви міста;

is_gmail — логічний індикатор email-адрес з доменом gmail.com.

5. Фільтрація та сегментація даних

Створено підвибірки даних за різними умовами:

користувачі з email-доменом gmail.com;

компанії з «LLC» або «Ltd» у назві;

користувачі з міста London;

компанії з довгою назвою (4 слова і більше);

позиційні вибірки за допомогою iloc().

6. Групування та статистика

Виконано базовий статистичний аналіз:

підраховано кількість користувачів у кожному місті;

визначено ТОП-5 міст за кількістю записів;

визначено ТОП-5 email-доменів;

обчислено кількість унікальних доменів.

7. Експорт результатів

Очищений датасет збережено у форматі CSV.

Окрему вибірку користувачів Gmail експортовано у CSV.

Статистичні результати збережено у Excel-файл з кількома аркушами.

Висновки

У ході проєкту реалізовано повний ETL-процес для реального датасету.
Дані були очищені, структуровані та підготовлені до подальшого аналізу.
Найбільш корисними етапами стали перевірка якості даних та створення нових аналітичних ознак.
У майбутньому проєкт можна розширити додатковими перевірками якості даних та візуалізаціями.

Використані бібліотеки

pandas

numpy
